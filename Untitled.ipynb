{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fe1201-ab67-471d-b44b-1fc15d3cc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomApply\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d58540-44a6-43ea-b963-9beab83a2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "train_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200fe73e-8dea-4872-b1fd-9ae653203cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        #print(in_channels, out_channels)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels * 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c23a3fc-aa99-44a2-a199-f6c7fb1c32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, init_block, init_stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            BottleNeck(in_channels, out_channels, stride=init_stride)\n",
    "        )\n",
    "\n",
    "        self.init_stride = init_stride\n",
    "        self.init_block = init_block\n",
    "\n",
    "        if init_block:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * 4, kernel_size=1, stride=init_stride),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "            #print(\"here0\", in_channels, out_channels * 4, init_stride)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"here1\", x.shape, self.init_stride, self.init_block)\n",
    "        x = self.shortcut(x) + self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        #print(\"here2\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5367143-b027-4e88-bd81-e2065c45689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, nblk=[3,4,6,3], nker=64, num_classes=8):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, nker, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(nker),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        layers=[]\n",
    "\n",
    "        layers.append(ResBlock(nker, 64, init_block=True))\n",
    "        nker = nker * 4\n",
    "        for i in range(nblk[0]-1):\n",
    "            layers.append(ResBlock(nker, 64, init_block=False))\n",
    "\n",
    "        layers.append(ResBlock(nker, 128, init_block=True, init_stride=2))\n",
    "        nker = nker * 2\n",
    "        for i in range(nblk[1]-1):\n",
    "            layers.append(ResBlock(nker, 128, init_block=False))\n",
    "\n",
    "        layers.append(ResBlock(nker, 256, init_block=True, init_stride=2))\n",
    "        nker = nker * 2\n",
    "        for i in range(nblk[2]-1):\n",
    "            layers.append(ResBlock(nker, 256, init_block=False))\n",
    "\n",
    "        layers.append(ResBlock(nker, 512, init_block=True, init_stride=2))\n",
    "        nker = nker * 2\n",
    "        for i in range(nblk[3]-1):\n",
    "            layers.append(ResBlock(nker, 512, init_block=False))\n",
    "\n",
    "        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.rnt = nn.Sequential(*layers)\n",
    "\n",
    "        self.fc = nn.Linear(nker, num_classes)\n",
    "        \n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "        #print(nker)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.rnt(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "724842c8-69ef-4df1-bbff-19b1cb25244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        nn.init.kaiming_uniform_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b776f8-4f3d-4564-a3ca-7d9d5aa25703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor shape is : torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "model_test = ResNet()\n",
    "model_test.apply(init_weights)\n",
    "\n",
    "# Random input\n",
    "x = torch.randn((1, 3, 150, 150))\n",
    "\n",
    "# Forward\n",
    "out = model_test(x)\n",
    "\n",
    "# Check the output shape\n",
    "print(\"Output tensor shape is :\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "094c8ee4-b3e2-490e-9929-b32313a72eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(Dataset):\n",
    "    def __init__(self, csv, transform):\n",
    "        self.csv = csv\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def read_image(self, index):\n",
    "        img_path = self.csv.iloc[index]['path']\n",
    "        image = Image.open(img_path)\n",
    "        return image\n",
    "        \n",
    "    def get_mask_label(self, index):\n",
    "        mask_label = self.csv.iloc[index]['mask']\n",
    "        if mask_label == 'mask':\n",
    "            return 0\n",
    "        elif mask_label == 'incorrect':\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    def get_gender_label(self, index):\n",
    "        gender_label = self.csv.iloc[index]['gender']\n",
    "\n",
    "        if gender_label == 'male':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_age_label(self, index):\n",
    "        age_label = self.csv.iloc[index]['age']\n",
    "\n",
    "        if age_label < 30:\n",
    "            return 0\n",
    "        elif age_label < 60:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "        \n",
    "    def __get__item(self, index):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class MaskMultiLabelDataset(MaskBaseDataset):\n",
    "    num_classes = 3 + 2 + 3\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        # multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, (mask_label, gender_label, age_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce6074f-f1a5-4df1-8224-9767be149825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3c9de4a-62d6-4d24-947e-79ffb6d386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5174bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet50#, ResNet50_Weights\n",
    "\n",
    "# def load_pretrained_weights(model, pretrained_model):\n",
    "#     pretrained_dict = pretrained_model.state_dict()\n",
    "#     model_dict = model.state_dict()\n",
    "    \n",
    "#     print(pretrained_dict)\n",
    "#     print(model_dict)\n",
    "    \n",
    "# model = ResNet(num_classes=8)#.to(device)\n",
    "# pretrained_model = resnet50(pretrained=True)\n",
    "# pretrained_dict = pretrained_model.state_dict()\n",
    "# model_dict = model.state_dict()\n",
    "    \n",
    "# print(pretrained_dict)\n",
    "# print(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ab5bad-b8cd-4b99-bb96-032408b5d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in 1-100 0.9021756497025489\n",
      "Loss in 1-200 0.5408713603019715\n",
      "Epoch [1/50], Loss: 0.9655, 0.6660\n",
      "Epoch [1/50], accuracy : 0.7386, f1_score : 0.7315\n",
      "Loss in 2-100 0.41467378988862036\n",
      "Loss in 2-200 0.37361507415771483\n",
      "Epoch [2/50], Loss: 0.3738, 0.3778\n",
      "Epoch [2/50], accuracy : 0.8380, f1_score : 0.8368\n",
      "Loss in 3-100 0.3049144271016121\n",
      "Loss in 3-200 0.28636482790112494\n",
      "Epoch [3/50], Loss: 0.1674, 0.2867\n",
      "Epoch [3/50], accuracy : 0.8979, f1_score : 0.8961\n",
      "Loss in 4-100 0.23585030268877744\n",
      "Loss in 4-200 0.22025424502789975\n",
      "Epoch [4/50], Loss: 0.4991, 0.2250\n",
      "Epoch [4/50], accuracy : 0.9362, f1_score : 0.9346\n",
      "Loss in 5-100 0.1872155051678419\n",
      "Loss in 5-200 0.15228873454034328\n",
      "Epoch [5/50], Loss: 0.0984, 0.1652\n",
      "Epoch [5/50], accuracy : 0.9267, f1_score : 0.9269\n",
      "Loss in 6-100 0.16184934839606285\n",
      "Loss in 6-200 0.13323659390211107\n",
      "Epoch [6/50], Loss: 0.1053, 0.1475\n",
      "Epoch [6/50], accuracy : 0.9537, f1_score : 0.9530\n",
      "Loss in 7-100 0.12087287686765194\n",
      "Loss in 7-200 0.10799279652535915\n",
      "Epoch [7/50], Loss: 0.0819, 0.1112\n",
      "Epoch [7/50], accuracy : 0.9725, f1_score : 0.9725\n",
      "Loss in 8-100 0.08456640562042594\n",
      "Loss in 8-200 0.07237341123633087\n",
      "Epoch [8/50], Loss: 0.0315, 0.0800\n",
      "Epoch [8/50], accuracy : 0.9666, f1_score : 0.9666\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "all_csv = pd.read_csv(os.path.join(train_dir, 'train_data.csv'))\n",
    "\n",
    "train_csv, val_csv = train_test_split(all_csv, test_size=0.15, random_state=42)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomApply([AddGaussianNoise(0.5, 0.2)]),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "train_dataset = MaskMultiLabelDataset(train_csv, transform)\n",
    "val_dataset = MaskMultiLabelDataset(val_csv, transform)\n",
    "\n",
    "num_classes = MaskMultiLabelDataset.num_classes\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def multi_label_to_class(mask_label, gender_label, age_label):\n",
    "    return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#model = ResNet(num_classes=8)#.to(device)\n",
    "#model.apply(init_weights)\n",
    "model_PATH = '/opt/ml/test/model.pt'\n",
    "\n",
    "# pretrained 모델을 load하여 사용\n",
    "model = timm.create_model('resnet18', num_classes=MaskMultiLabelDataset.num_classes, pretrained=True)\n",
    "\n",
    "# pretrained된 모델의 가중치를 사용하도록 하는 코드\n",
    "# pretrained_model = resnet50(pretrained=True)\n",
    "# load_pretrained_weights = (model, pretrained_model)\n",
    "\n",
    "# 기존 모델 가중치를 load하여 사용하는 코드\n",
    "# if os.path.isfile(model_PATH):\n",
    "#     model.load_state_dict(torch.load(model_PATH))\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    lslist = []\n",
    "    lossv = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        images, (mask_labels, gender_labels, age_labels) = train_batch\n",
    "        images = images.to(device)\n",
    "        mask_labels = mask_labels.to(device)\n",
    "        gender_labels = gender_labels.to(device)\n",
    "        age_labels = age_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        (mask_outputs, gender_outputs, age_outputs) = torch.split(outputs, [3,2,3], dim=1)\n",
    "\n",
    "        mask_loss = criterion(mask_outputs, mask_labels)\n",
    "        gender_loss = criterion(gender_outputs, gender_labels)\n",
    "        age_loss = criterion(age_outputs, age_labels)\n",
    "\n",
    "        loss = mask_loss + gender_loss + (1.3 * age_loss)\n",
    "\n",
    "        lslist.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lossv += loss.item()\n",
    "        if idx % 100 == 99:\n",
    "            print(f'Loss in {epoch+1}-{idx+1}', lossv / 100)\n",
    "            lossv = 0\n",
    "            \n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        torch.save(model.state_dict(), model_PATH)\n",
    "\n",
    "    avg_loss = sum(lslist)/len(lslist)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, (mask_labels, gender_labels, age_labels) in val_loader:\n",
    "            images = images.to(device)\n",
    "            mask_labels = mask_labels.to(device)\n",
    "            gender_labels = gender_labels.to(device)\n",
    "            age_labels = age_labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            (mask_outputs, gender_outputs, age_outputs) = torch.split(outputs, [3, 2, 3], dim=1)\n",
    "\n",
    "            mask_preds = torch.argmax(mask_outputs, dim=1)\n",
    "            gender_preds = torch.argmax(gender_outputs, dim=1)\n",
    "            age_preds = torch.argmax(age_outputs, dim=1)\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                y_true.append(multi_label_to_class(mask_labels[i].item(), gender_labels[i].item(), age_labels[i].item()))\n",
    "                y_pred.append(multi_label_to_class(mask_preds[i].item(), gender_preds[i].item(), age_preds[i].item()))\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, {:.4f}'.format(epoch+1, epochs, loss.item(), avg_loss))\n",
    "    print('Epoch [{}/{}], accuracy : {:.4f}, f1_score : {:.4f}'.format(epoch+1, epochs, accuracy, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59cab49-e618-4913-b2d8-06d199d4521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), model_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskTestDataset(MaskBaseDataset):\n",
    "    def __init__(self, csv, image_dir, transform):\n",
    "        super().__init__(csv, transform)\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def read_image(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.csv.iloc[index]['ImageID'])\n",
    "        image = Image.open(img_path)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe09c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = os.path.join(test_dir, 'images')\n",
    "test_dataset = MaskTestDataset(submission, test_image_dir, transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        (mask_outputs, gender_outputs, age_outputs) = torch.split(outputs, [3, 2, 3], dim=1)\n",
    "\n",
    "        mask_preds = torch.argmax(mask_outputs, dim=1)\n",
    "        gender_preds = torch.argmax(gender_outputs, dim=1)\n",
    "        age_preds = torch.argmax(age_outputs, dim=1)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            predictions.append((mask_preds[i].item(), gender_preds[i].item(), age_preds[i].item()))\n",
    "\n",
    "for i, (mask_pred, gender_pred, age_pred) in enumerate(predictions):\n",
    "    submission.loc[i, 'ans'] = multi_label_to_class(mask_pred, gender_pred, age_pred)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d37ea-a079-4ed0-8663-09129884403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.eval()\n",
    "# # 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "# all_predictions = []\n",
    "# for images, labels in train_loader:\n",
    "#     with torch.no_grad():\n",
    "#         images = images.to(device)\n",
    "#         pred = model(images)\n",
    "#         print(pred)\n",
    "#         pred = pred.argmax(dim=-1)\n",
    "#         all_predictions.extend(pred.cpu().numpy())\n",
    "# submission['ans'] = all_predictions\n",
    "\n",
    "# # 제출할 파일을 저장합니다.\n",
    "# submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "# print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd72ce0-60f9-4e5a-8f25-6deafe54f987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5327bbc-b872-4778-a949-be3970345426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
